{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP42uVVIf07uXKrSIQCT8ox",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joe-jachim/pytorch-playground/blob/main/mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_es8lgNsasI"
      },
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import random_split, DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wZBMTy-si-j"
      },
      "source": [
        "# Define  model\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(28 * 28, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.1),\n",
        "    nn.Linear(64, 10)\n",
        ").cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "_H2n2Tk1_4_u",
        "outputId": "0ff073f4-5d11-4aea-e4cb-1a53098873fd"
      },
      "source": [
        "'''\n",
        "# Define a more flexible model\n",
        "class ResNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.l1 = nn.Linear(28 * 28, 64)\n",
        "    self.l2 = nn.Linear(64, 64)\n",
        "    self.l3 = nn.Linear(64, 10)\n",
        "    self.do = nn.Dropout(0.1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    h1 = nn.functional.relu(self.l1(x))\n",
        "    h2 = nn.functional.relu(self.l2(h1))\n",
        "    do = self.do(h2 + h1)\n",
        "    logits = self.l3(do)\n",
        "    return logits\n",
        "\n",
        "  #def backward(self, x)\n",
        "\n",
        "model = ResNet().cuda()\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# Define a more flexible model\\nclass ResNet(nn.Module):\\n  def __init__(self):\\n    super().__init__()\\n    self.l1 = nn.Linear(28 * 28, 64)\\n    self.l2 = nn.Linear(64, 64)\\n    self.l3 = nn.Linear(64, 10)\\n    self.do = nn.Dropout(0.1)\\n\\n  def forward(self, x):\\n    h1 = nn.functional.relu(self.l1(x))\\n    h2 = nn.functional.relu(self.l2(h1))\\n    do = self.do(h2 + h1)\\n    logits = self.l3(do)\\n    return logits\\n\\n  #def backward(self, x)\\n\\nmodel = ResNet().cuda()\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cytkHE20tidf"
      },
      "source": [
        "# Define optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JW6LbkDrzd2q"
      },
      "source": [
        "# Define my loss\n",
        "loss = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9A8NPPgwWpI"
      },
      "source": [
        "# Train, Val split\n",
        "train_data = datasets.MNIST('data', train=True, download=True, transform=transforms.ToTensor())\n",
        "train, val = random_split(train_data, [55000, 5000])\n",
        "train_loader = DataLoader(train, batch_size=32)\n",
        "val_loader = DataLoader(val, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnO7CDOCt2O2",
        "outputId": "1d8e4a07-c44a-4401-89fc-5f2e3b9b58e7"
      },
      "source": [
        "# Define my loss\n",
        "nb_epochs = 5\n",
        "for epoch in range(nb_epochs):\n",
        "  losses = list()\n",
        "  model.train()\n",
        "  for batch in train_loader:\n",
        "    x, y = batch\n",
        "    \n",
        "    x = x.view(x.size(0), -1).cuda()\n",
        "\n",
        "    # Forward\n",
        "    l = model(x)  # l: logits\n",
        "\n",
        "    # Compute the objective function\n",
        "    J = loss(l, y.cuda())\n",
        "\n",
        "    # Cleaning the gradient\n",
        "    model.zero_grad()\n",
        "\n",
        "    # Complete partial derivates of J wrt to params\n",
        "    J.backward()\n",
        "\n",
        "    # Step in the opposite direction of the gradient\n",
        "    optimizer.step()\n",
        "\n",
        "    losses.append(J.item())\n",
        "\n",
        "  accuracies = list()\n",
        "  val_losses = list()\n",
        "  model.eval()\n",
        "  for batch in val_loader:\n",
        "    x, y = batch\n",
        "    \n",
        "    x = x.view(x.size(0), -1).cuda()\n",
        "\n",
        "    # Forward\n",
        "    with torch.no_grad():\n",
        "      l = model(x)  # l: logits\n",
        "\n",
        "    # Compute the objective function\n",
        "    J = loss(l, y.cuda())\n",
        "\n",
        "    val_losses.append(J.item())\n",
        "    accuracies.append(y.eq(l.detach().argmax(dim=1).cpu()).float().mean())\n",
        "\n",
        "  print(f'epoch {epoch + 1}, train loss {torch.tensor(losses).mean():.2f}', end=', ')\n",
        "  print(f'val loss {torch.tensor(val_losses).mean():.2f}', end=', ')\n",
        "  print(f'val acc {torch.tensor(accuracies).mean():.2f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1, train loss 1.30, val loss 0.51, val acc 0.86\n",
            "epoch 2, train loss 0.45, val loss 0.36, val acc 0.90\n",
            "epoch 3, train loss 0.36, val loss 0.31, val acc 0.91\n",
            "epoch 4, train loss 0.31, val loss 0.28, val acc 0.92\n",
            "epoch 5, train loss 0.28, val loss 0.26, val acc 0.92\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxNmqsxbwVLZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}